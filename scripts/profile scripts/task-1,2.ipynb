{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding Directories"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "``` \n",
    "We have 4 paths here,\n",
    "\n",
    "    1. path_dir is the source where all the sub directories are located\n",
    "    2. src_dir is the source for text input files\n",
    "    3. dst_tmp_ir is destination path for temporary csv files\n",
    "    4. dst_dir is the destination path for final csv files\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_dir = r'C:\\Users\\ydjoe\\Documents\\nlp\\personalized-dialog-dataset\\small'\n",
    "src_dir = os.path.join(path_dir,'txt files')\n",
    "dst_tmp_dir = os.path.join(path_dir,'csv files temp')\n",
    "dst_dir = os.path.join(path_dir,'csv files')\n",
    "\n",
    "lst_files = os.listdir(src_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checking Files in the Source file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 personalized-dialog-task1-API-calls-dev.txt\n",
      "1 personalized-dialog-task1-API-calls-trn.txt\n",
      "2 personalized-dialog-task1-API-calls-tst-OOV.txt\n",
      "3 personalized-dialog-task1-API-calls-tst.txt\n",
      "4 personalized-dialog-task2-API-refine-dev.txt\n",
      "5 personalized-dialog-task2-API-refine-trn.txt\n",
      "6 personalized-dialog-task2-API-refine-tst-OOV.txt\n",
      "7 personalized-dialog-task2-API-refine-tst.txt\n",
      "8 personalized-dialog-task3-options-dev.txt\n",
      "9 personalized-dialog-task3-options-trn.txt\n",
      "10 personalized-dialog-task3-options-tst-OOV.txt\n",
      "11 personalized-dialog-task3-options-tst.txt\n",
      "12 personalized-dialog-task4-info-dev.txt\n",
      "13 personalized-dialog-task4-info-trn.txt\n",
      "14 personalized-dialog-task4-info-tst-OOV.txt\n",
      "15 personalized-dialog-task4-info-tst.txt\n",
      "16 personalized-dialog-task5-full-dialogs-dev.txt\n",
      "17 personalized-dialog-task5-full-dialogs-trn.txt\n",
      "18 personalized-dialog-task5-full-dialogs-tst-OOV.txt\n",
      "19 personalized-dialog-task5-full-dialogs-tst.txt\n"
     ]
    }
   ],
   "source": [
    "iter_tp = 0\n",
    "for iter_fl in lst_files:\n",
    "    print(iter_tp,iter_fl)\n",
    "    iter_tp+=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run Single File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ydjoe\\Documents\\nlp\\personalized-dialog-dataset\\full\\txt files\\personalized-dialog-task1-API-calls-dev.txt\n"
     ]
    }
   ],
   "source": [
    "fl_no = 0\n",
    "path_final = os.path.join(src_dir,lst_files[fl_no])\n",
    "print(path_final)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating temp CSV file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "``` temp csv file contains profile,knowldgebase as seperate columns i.e we are yet to add tags such as <user> <profile> <query> <system> etc.. ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(36086, 5)\n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame([])  \n",
    "\n",
    "## Initializing df to add data to\n",
    "\n",
    "path_to_use = path_final\n",
    "ct = 0\n",
    "\n",
    "with open(path_to_use) as topo_file:\n",
    "\n",
    "    ## Open the text file from given path\n",
    "\n",
    "    cnt = 0\n",
    "    cnt_sub = 0\n",
    "\n",
    "    ## cnt_sub is a Counter \n",
    "\n",
    "    ar_3,ar_4 = [],[]\n",
    "    ar_1,ar_2 = [],[]\n",
    "\n",
    "    ## we are initializing 4 arrays, each array stores the following\n",
    "    ## Gender, age-group , Call , Response , Counter\n",
    "    ## Gender (ar_1) and age-group (ar_2) are self explainable\n",
    "    ## Call has the question asked (ar_3)\n",
    "    ## Response is the answer given (ar_4)\n",
    "    ## Counter is to understand where a new conversation starts\n",
    "\n",
    "    for line in topo_file:\n",
    "\n",
    "        ## Go through each line of the text file\n",
    "\n",
    "        line = line.strip()    \n",
    "        if not line.strip(): continue\n",
    "\n",
    "        ## If the line is empty continue to next line\n",
    "\n",
    "        init_num = re.findall(r'\\d+',line)        \n",
    "\n",
    "        ## identifying the number before each line\n",
    "\n",
    "        if init_num[0]=='1':\n",
    "\n",
    "            ## The first line has the profile, So Identifying 1\n",
    "            \n",
    "            line_splits = line[1:].split()\n",
    "\n",
    "            ## We split the line 1 to get Gender and age\n",
    "\n",
    "            ar_1.append(line_splits[0])\n",
    "\n",
    "            ## Appending Gender to array 1\n",
    "\n",
    "            ar_2.append(line_splits[1])\n",
    "\n",
    "            ## Appending Age to array 2\n",
    "\n",
    "            ar_5 = cnt\n",
    "\n",
    "            ## Since Profile is to be appended to all examples, \n",
    "            ## we have to identify number of Call and Responses in a SIngle Conversation\n",
    "\n",
    "            cnt+=1\n",
    "\n",
    "            if len(ar_3)==0: continue\n",
    "\n",
    "            ## Check if we are on line 1 of 1st conversation.\n",
    "            ## if we are skip for now\n",
    "            \n",
    "            data = list(\n",
    "                zip(\n",
    "                    [ar_1[0]]*len(ar_3),\n",
    "                    [ar_2[0]]*len(ar_3),                    \n",
    "                    ar_3,\n",
    "                    ar_4,\n",
    "                    [ar_5]*len(ar_3)       \n",
    "                    ))\n",
    "\n",
    "            df = df.append(data,ignore_index=True)\n",
    "            cnt_sub = 0\n",
    "            ar_3,ar_4 = [],[]\n",
    "            ar_1.pop(0)\n",
    "            ar_2.pop(0)\n",
    "\n",
    "            ## Add the data of first Conversation to the main dataframe defined\n",
    "            ## ReSet the counter, Call and Response arrays\n",
    "            ## Since Gender and age-group are single values pop them from begining , essentially resetting them  \n",
    "            continue\n",
    "\n",
    "\n",
    "        line_splits = line[2:].split('\\t')\n",
    "        ar_3.append(line_splits[0])\n",
    "        ar_4.append(line_splits[1])\n",
    "\n",
    "        ## Splitting Call and Response\n",
    "        ## Addinig Call and Response to arrays 3 & 4\n",
    "\n",
    "        cnt_sub+=1\n",
    "\n",
    "        ## Incrementing Counter \n",
    "\n",
    "df = df.rename(columns={\n",
    "     0: 'Gender',\n",
    "     1: 'Age',\n",
    "     2: 'Call',\n",
    "     3: 'Response',\n",
    "     4: 'Count'\n",
    "     })\n",
    "\n",
    "## Adding Column Names to our dataframe \n",
    "\n",
    "print(df.shape)\n",
    "fl_dst = lst_files[fl_no][:-3] + 'csv'\n",
    "path_dst_tmp = os.path.join(dst_tmp_dir,fl_dst)\n",
    "\n",
    "## getting file name and appending it to the destination path\n",
    "\n",
    "df.to_csv(path_dst_tmp,index=False)\n",
    "\n",
    "## Writing File to temp csv file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final CSV File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(36086, 2)\n"
     ]
    }
   ],
   "source": [
    "TAGS = [\n",
    "\n",
    "    '<profile> ',\n",
    "    ' <context>',\n",
    "    ' <user> ',\n",
    "    ' <system> ',\n",
    "    ' <query> ']\n",
    "\n",
    "\n",
    "## Defining tags we have to use in our final CSV file\n",
    "\n",
    "\n",
    "mn_ar_1 = []\n",
    "mn_ar_2 = []\n",
    "mn_ar_3 = []\n",
    "prev_count = 0\n",
    "prev_string = ''\n",
    "\n",
    "for i in range(len(df)):    \n",
    "    \n",
    "    ## Go through each line of the temp CSV file\n",
    "    ## From the Counter Column Identify beginning of each Conversation \n",
    "\n",
    "    if df.iloc[i][4]!=prev_count:\n",
    "        prev_string = ''\n",
    "        prev_count = df.iloc[i][4]\n",
    "    \n",
    "    a2 = df.iloc[i][2]\n",
    "    a3 = df.iloc[i][3]    \n",
    "\n",
    "    ## get call and Response Column\n",
    "\n",
    "\n",
    "    call_string = prev_string + TAGS[4]+ a2    \n",
    "    prev_string = prev_string + TAGS[2]+  a2 + TAGS[3] + a3\n",
    "    to_append = TAGS[0]+ line\n",
    "\n",
    "    ## adding the tags wherever they are appropriate\n",
    "    ## for the present line add only <Query> tag ( which is tag[4])\n",
    "    ## for next set of lines in the conversation add <User> and <Sytem> tags ( tag[2],tag[3])\n",
    "    ## we do this until the counter identifies a new conversation starting, at the beginning of the loop    \n",
    "\n",
    "\n",
    "    mn_ar_1.append(call_string)\n",
    "    mn_ar_2.append(a3)\n",
    "\n",
    "    ## appending new Call and Responses to arrays\n",
    "\n",
    "ndf = pd.DataFrame(            \n",
    "            list(zip(\n",
    "                mn_ar_1,mn_ar_2                  \n",
    "                )),\n",
    "\n",
    "            columns =[\n",
    "                'Call',\n",
    "                'Response'\n",
    "                ]\n",
    "                ) \n",
    "\n",
    "## Creating new dataframe with new set of Call and Response columns\n",
    "\n",
    "df['Profile'] = df['Gender'] + ' ' +df['Age']\n",
    "ndf['Call'] = TAGS[0]+ df['Profile'] + TAGS[1] + ndf['Call']\n",
    "\n",
    "## Since all Lines would have the Profile, adding the profile tag at the begining \n",
    "## of each line and appending it to the new df\n",
    "\n",
    "\n",
    "print(ndf.shape)\n",
    "fl_dst = lst_files[fl_no][:-3] + '.csv'\n",
    "path_dst = os.path.join(dst_dir,fl_dst)\n",
    "\n",
    "## getting file name and appending it to the destination path\n",
    "\n",
    "ndf.to_csv(path_dst,index=False)\n",
    "    \n",
    "## Writing File to Final csv file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining the above steps as a Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_df(path_final):\n",
    "    df = pd.DataFrame([])\n",
    "    path_to_use = path_final\n",
    "    ct = 0\n",
    "    with open(path_to_use) as topo_file:\n",
    "        cnt = 0\n",
    "        cnt_sub = 0\n",
    "        ar_3,ar_4 = [],[]\n",
    "        ar_1,ar_2 = [],[]\n",
    "\n",
    "        for line in topo_file:\n",
    "            # if ct>120: break\n",
    "            # ct+=1\n",
    "\n",
    "            line = line.strip()    \n",
    "            if not line.strip(): continue\n",
    "\n",
    "            init_num = re.findall(r'\\d+',line)        \n",
    "\n",
    "            if init_num[0]=='1':\n",
    "\n",
    "                #print(line)\n",
    "                line_splits = line[1:].split()\n",
    "                ar_1.append(line_splits[0])\n",
    "                ar_2.append(line_splits[1])\n",
    "                ar_5 = cnt\n",
    "                cnt+=1\n",
    "\n",
    "                if len(ar_3)==0: continue\n",
    "                \n",
    "                data = list(\n",
    "                    zip(\n",
    "                        [ar_1[0]]*len(ar_3),\n",
    "                        [ar_2[0]]*len(ar_3),                    \n",
    "                        ar_3,\n",
    "                        ar_4,\n",
    "                        [ar_5]*len(ar_3)       \n",
    "                        ))\n",
    "\n",
    "                df = df.append(data,ignore_index=True)\n",
    "                cnt_sub = 0\n",
    "                ar_3,ar_4 = [],[]\n",
    "                ar_1.pop(0)\n",
    "                ar_2.pop(0)\n",
    "                continue\n",
    "\n",
    "            line_splits = line[2:].split('\\t')\n",
    "            ar_3.append(line_splits[0])\n",
    "            ar_4.append(line_splits[1])\n",
    "            cnt_sub+=1\n",
    "\n",
    "    df = df.rename(columns={\n",
    "        0: 'Gender',\n",
    "        1: 'Age',\n",
    "        2: 'Call',\n",
    "        3: 'Response',\n",
    "        4: 'Count'\n",
    "        })\n",
    "    print(df.shape)\n",
    "    fl_dst = lst_files[fl_no][:-3] + 'csv'\n",
    "    path_dst_tmp = os.path.join(dst_tmp_dir,fl_dst)\n",
    "    df.to_csv(path_dst_tmp,index=False)\n",
    "    return df\n",
    "\n",
    "TAGS = [\n",
    "\n",
    "    '<profile> ',\n",
    "    ' <context>',\n",
    "    ' <user> ',\n",
    "    ' <system> ',\n",
    "    ' <query> ']\n",
    "    \n",
    "def add_context(df):\n",
    "    prev_count = 0\n",
    "    txt = []\n",
    "    for i in range(len(df)):    \n",
    "        if df.iloc[i][4]!=prev_count:\n",
    "            prev_count = df.iloc[i][4]\n",
    "            txt.append('')\n",
    "            continue\n",
    "        txt.append(' <context>')  \n",
    "    df['TAG'] = txt\n",
    "    return df\n",
    "\n",
    "\n",
    "def parse_from_df(df):\n",
    "    c = 0\n",
    "    mn_ar_1 = []\n",
    "    mn_ar_2 = []\n",
    "    mn_ar_3 = []\n",
    "    prev_count = 0\n",
    "    prev_string = ''\n",
    "    for i in range(len(df)):    \n",
    "        #if c > 100: break\n",
    "        c+=1    \n",
    "\n",
    "        if df.iloc[i][4]!=prev_count:\n",
    "            prev_string = ''\n",
    "            prev_count = df.iloc[i][4]\n",
    "        \n",
    "        a2 = df.iloc[i][2]\n",
    "        a3 = df.iloc[i][3]    \n",
    "        call_string = prev_string + TAGS[4]+ a2    \n",
    "        prev_string = prev_string + TAGS[2]+ a2 + TAGS[3] + a3\n",
    "        # print(a2)\n",
    "        # print('call: ',call_string)\n",
    "        # print('prev: ',call_string)\n",
    "        # print(a3)\n",
    "        mn_ar_1.append(call_string)\n",
    "        mn_ar_2.append(a3)\n",
    "\n",
    "    ndf = pd.DataFrame(            \n",
    "                list(zip(\n",
    "                    mn_ar_1,mn_ar_2                  \n",
    "                    )),\n",
    "\n",
    "                columns =[\n",
    "                    'Call',\n",
    "                    'Response'\n",
    "                    ]\n",
    "                    ) \n",
    "\n",
    "    df['Profile'] = df['Gender'] + ' ' +df['Age']\n",
    "    ndf['Call'] = TAGS[0]+ df['Profile'] + df['TAG'] + ndf['Call']\n",
    "\n",
    "    print(ndf.shape)\n",
    "    fl_dst = lst_files[fl_no][:-3] + '.csv'\n",
    "    path_dst = os.path.join(dst_dir,fl_dst)\n",
    "    ndf.to_csv(path_dst,index=False)       "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A loop to get the index of Files to run "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 C:\\Users\\ydjoe\\Documents\\nlp\\personalized-dialog-dataset\\small\\txt files\\personalized-dialog-task1-API-calls-dev.txt\n",
      "1 C:\\Users\\ydjoe\\Documents\\nlp\\personalized-dialog-dataset\\small\\txt files\\personalized-dialog-task1-API-calls-trn.txt\n",
      "2 C:\\Users\\ydjoe\\Documents\\nlp\\personalized-dialog-dataset\\small\\txt files\\personalized-dialog-task1-API-calls-tst-OOV.txt\n",
      "3 C:\\Users\\ydjoe\\Documents\\nlp\\personalized-dialog-dataset\\small\\txt files\\personalized-dialog-task1-API-calls-tst.txt\n",
      "4 C:\\Users\\ydjoe\\Documents\\nlp\\personalized-dialog-dataset\\small\\txt files\\personalized-dialog-task2-API-refine-dev.txt\n",
      "5 C:\\Users\\ydjoe\\Documents\\nlp\\personalized-dialog-dataset\\small\\txt files\\personalized-dialog-task2-API-refine-trn.txt\n",
      "6 C:\\Users\\ydjoe\\Documents\\nlp\\personalized-dialog-dataset\\small\\txt files\\personalized-dialog-task2-API-refine-tst-OOV.txt\n",
      "7 C:\\Users\\ydjoe\\Documents\\nlp\\personalized-dialog-dataset\\small\\txt files\\personalized-dialog-task2-API-refine-tst.txt\n",
      "8 C:\\Users\\ydjoe\\Documents\\nlp\\personalized-dialog-dataset\\small\\txt files\\personalized-dialog-task3-options-dev.txt\n"
     ]
    }
   ],
   "source": [
    "for i in range(0,9):\n",
    "    fl_no = i\n",
    "    path_final = os.path.join(src_dir,lst_files[fl_no])\n",
    "    print(i,path_final)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running the loop to preprocess all the similar files at once"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6008, 5)\n",
      "(6008, 2)\n",
      "(6016, 5)\n",
      "(6016, 2)\n",
      "(6014, 5)\n",
      "(6014, 2)\n",
      "(5931, 5)\n",
      "(5931, 2)\n",
      "(9502, 5)\n",
      "(9502, 2)\n",
      "(9488, 5)\n",
      "(9488, 2)\n",
      "(9450, 5)\n",
      "(9450, 2)\n",
      "(9453, 5)\n",
      "(9453, 2)\n"
     ]
    }
   ],
   "source": [
    "for i in range(0,8):\n",
    "    fl_no = i\n",
    "    path_final = os.path.join(src_dir,lst_files[fl_no])\n",
    "    df = convert_to_df(path_final)\n",
    "    df = add_context(df)\n",
    "    parse_from_df(df)\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "540e2923c3b50c5b50181b56164d273ff885d61dafa41268e9f428c1d3e4caa0"
  },
  "kernelspec": {
   "display_name": "Python 3.9.6 ('venv')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
