{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## deploy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_dir = r'C:\\Users\\ydjoe\\Documents\\nlp\\personalized-dialog-dataset\\small'\n",
    "src_dir = os.path.join(path_dir,'txt files')\n",
    "dst_tmp_dir = os.path.join(path_dir,'csv files temp')\n",
    "dst_dir = os.path.join(path_dir,'csv files')\n",
    "\n",
    "lst_files = os.listdir(src_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 personalized-dialog-task1-API-calls-dev.txt\n",
      "1 personalized-dialog-task1-API-calls-trn.txt\n",
      "2 personalized-dialog-task1-API-calls-tst-OOV.txt\n",
      "3 personalized-dialog-task1-API-calls-tst.txt\n",
      "4 personalized-dialog-task2-API-refine-dev.txt\n",
      "5 personalized-dialog-task2-API-refine-trn.txt\n",
      "6 personalized-dialog-task2-API-refine-tst-OOV.txt\n",
      "7 personalized-dialog-task2-API-refine-tst.txt\n",
      "8 personalized-dialog-task3-options-dev.txt\n",
      "9 personalized-dialog-task3-options-trn.txt\n",
      "10 personalized-dialog-task3-options-tst-OOV.txt\n",
      "11 personalized-dialog-task3-options-tst.txt\n",
      "12 personalized-dialog-task4-info-dev.txt\n",
      "13 personalized-dialog-task4-info-trn.txt\n",
      "14 personalized-dialog-task4-info-tst-OOV.txt\n",
      "15 personalized-dialog-task4-info-tst.txt\n",
      "16 personalized-dialog-task5-full-dialogs-dev.txt\n",
      "17 personalized-dialog-task5-full-dialogs-trn.txt\n",
      "18 personalized-dialog-task5-full-dialogs-tst-OOV.txt\n",
      "19 personalized-dialog-task5-full-dialogs-tst.txt\n"
     ]
    }
   ],
   "source": [
    "iter_tp = 0\n",
    "for iter_fl in lst_files:\n",
    "    print(iter_tp,iter_fl)\n",
    "    iter_tp+=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## task 1,2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ydjoe\\Documents\\nlp\\personalized-dialog-dataset\\full\\txt files\\personalized-dialog-task1-API-calls-dev.txt\n"
     ]
    }
   ],
   "source": [
    "fl_no = 0\n",
    "path_final = os.path.join(src_dir,lst_files[fl_no])\n",
    "print(path_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(36086, 5)\n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame([])\n",
    "path_to_use = path_final\n",
    "ct = 0\n",
    "with open(path_to_use) as topo_file:\n",
    "    cnt = 0\n",
    "    cnt_sub = 0\n",
    "    ar_3,ar_4 = [],[]\n",
    "    ar_1,ar_2 = [],[]\n",
    "\n",
    "    for line in topo_file:\n",
    "        # if ct>120: break\n",
    "        # ct+=1\n",
    "\n",
    "        line = line.strip()    \n",
    "        if not line.strip(): continue\n",
    "\n",
    "        init_num = re.findall(r'\\d+',line)        \n",
    "\n",
    "        if init_num[0]=='1':\n",
    "\n",
    "            #print(line)\n",
    "            line_splits = line[1:].split()\n",
    "            ar_1.append(line_splits[0])\n",
    "            ar_2.append(line_splits[1])\n",
    "            ar_5 = cnt\n",
    "            cnt+=1\n",
    "\n",
    "            if len(ar_3)==0: continue\n",
    "            \n",
    "            data = list(\n",
    "                zip(\n",
    "                    [ar_1[0]]*len(ar_3),\n",
    "                    [ar_2[0]]*len(ar_3),                    \n",
    "                    ar_3,\n",
    "                    ar_4,\n",
    "                    [ar_5]*len(ar_3)       \n",
    "                    ))\n",
    "\n",
    "            df = df.append(data,ignore_index=True)\n",
    "            cnt_sub = 0\n",
    "            ar_3,ar_4 = [],[]\n",
    "            ar_1.pop(0)\n",
    "            ar_2.pop(0)\n",
    "            continue\n",
    "\n",
    "        line_splits = line[2:].split('\\t')\n",
    "        ar_3.append(line_splits[0])\n",
    "        ar_4.append(line_splits[1])\n",
    "        cnt_sub+=1\n",
    "\n",
    "df = df.rename(columns={\n",
    "     0: 'Gender',\n",
    "     1: 'Age',\n",
    "     2: 'Call',\n",
    "     3: 'Response',\n",
    "     4: 'Count'\n",
    "     })\n",
    "print(df.shape)\n",
    "fl_dst = lst_files[fl_no][:-3] + 'csv'\n",
    "path_dst_tmp = os.path.join(dst_tmp_dir,fl_dst)\n",
    "df.to_csv(path_dst_tmp,index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(36086, 2)\n"
     ]
    }
   ],
   "source": [
    "TAGS = [\n",
    "\n",
    "    '<profile> ',\n",
    "    ' <context>',\n",
    "    ' <user> ',\n",
    "    ' <system> ',\n",
    "    ' <query> ']\n",
    "\n",
    "c = 0\n",
    "mn_ar_1 = []\n",
    "mn_ar_2 = []\n",
    "mn_ar_3 = []\n",
    "prev_count = 0\n",
    "prev_string = ''\n",
    "for i in range(len(df)):    \n",
    "    #if c > 100: break\n",
    "    c+=1    \n",
    "\n",
    "    if df.iloc[i][4]!=prev_count:\n",
    "        prev_string = ''\n",
    "        prev_count = df.iloc[i][4]\n",
    "    \n",
    "    a2 = df.iloc[i][2]\n",
    "    a3 = df.iloc[i][3]    \n",
    "    call_string = prev_string + TAGS[4]+ a2    \n",
    "    prev_string = prev_string + TAGS[2]+  a2 + TAGS[3] + a3\n",
    "    # print(a2)\n",
    "    # print('call: ',call_string)\n",
    "    # print('prev: ',call_string)\n",
    "    # print(a3)\n",
    "    to_append = TAGS[0]+ line\n",
    "    mn_ar_1.append(call_string)\n",
    "    mn_ar_2.append(a3)\n",
    "\n",
    "ndf = pd.DataFrame(            \n",
    "            list(zip(\n",
    "                mn_ar_1,mn_ar_2                  \n",
    "                )),\n",
    "\n",
    "            columns =[\n",
    "                'Call',\n",
    "                'Response'\n",
    "                ]\n",
    "                ) \n",
    "\n",
    "df['Profile'] = df['Gender'] + ' ' +df['Age']\n",
    "ndf['Call'] = TAGS[0]+ df['Profile'] + TAGS[1] + ndf['Call']\n",
    "\n",
    "print(ndf.shape)\n",
    "fl_dst = lst_files[fl_no][:-3] + '.csv'\n",
    "path_dst = os.path.join(dst_dir,fl_dst)\n",
    "ndf.to_csv(path_dst,index=False)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_df(path_final):\n",
    "    df = pd.DataFrame([])\n",
    "    path_to_use = path_final\n",
    "    ct = 0\n",
    "    with open(path_to_use) as topo_file:\n",
    "        cnt = 0\n",
    "        cnt_sub = 0\n",
    "        ar_3,ar_4 = [],[]\n",
    "        ar_1,ar_2 = [],[]\n",
    "\n",
    "        for line in topo_file:\n",
    "            # if ct>120: break\n",
    "            # ct+=1\n",
    "\n",
    "            line = line.strip()    \n",
    "            if not line.strip(): continue\n",
    "\n",
    "            init_num = re.findall(r'\\d+',line)        \n",
    "\n",
    "            if init_num[0]=='1':\n",
    "\n",
    "                #print(line)\n",
    "                line_splits = line[1:].split()\n",
    "                ar_1.append(line_splits[0])\n",
    "                ar_2.append(line_splits[1])\n",
    "                ar_5 = cnt\n",
    "                cnt+=1\n",
    "\n",
    "                if len(ar_3)==0: continue\n",
    "                \n",
    "                data = list(\n",
    "                    zip(\n",
    "                        [ar_1[0]]*len(ar_3),\n",
    "                        [ar_2[0]]*len(ar_3),                    \n",
    "                        ar_3,\n",
    "                        ar_4,\n",
    "                        [ar_5]*len(ar_3)       \n",
    "                        ))\n",
    "\n",
    "                df = df.append(data,ignore_index=True)\n",
    "                cnt_sub = 0\n",
    "                ar_3,ar_4 = [],[]\n",
    "                ar_1.pop(0)\n",
    "                ar_2.pop(0)\n",
    "                continue\n",
    "\n",
    "            line_splits = line[2:].split('\\t')\n",
    "            ar_3.append(line_splits[0])\n",
    "            ar_4.append(line_splits[1])\n",
    "            cnt_sub+=1\n",
    "\n",
    "    df = df.rename(columns={\n",
    "        0: 'Gender',\n",
    "        1: 'Age',\n",
    "        2: 'Call',\n",
    "        3: 'Response',\n",
    "        4: 'Count'\n",
    "        })\n",
    "    print(df.shape)\n",
    "    fl_dst = lst_files[fl_no][:-3] + 'csv'\n",
    "    path_dst_tmp = os.path.join(dst_tmp_dir,fl_dst)\n",
    "    df.to_csv(path_dst_tmp,index=False)\n",
    "    return df\n",
    "\n",
    "TAGS = [\n",
    "\n",
    "    '<profile> ',\n",
    "    ' <context>',\n",
    "    ' <user> ',\n",
    "    ' <system> ',\n",
    "    ' <query> ']\n",
    "    \n",
    "def add_context(df):\n",
    "    prev_count = 0\n",
    "    txt = []\n",
    "    for i in range(len(df)):    \n",
    "        if df.iloc[i][4]!=prev_count:\n",
    "            prev_count = df.iloc[i][4]\n",
    "            txt.append('')\n",
    "            continue\n",
    "        txt.append(' <context>')  \n",
    "    df['TAG'] = txt\n",
    "    return df\n",
    "\n",
    "\n",
    "def parse_from_df(df):\n",
    "    c = 0\n",
    "    mn_ar_1 = []\n",
    "    mn_ar_2 = []\n",
    "    mn_ar_3 = []\n",
    "    prev_count = 0\n",
    "    prev_string = ''\n",
    "    for i in range(len(df)):    \n",
    "        #if c > 100: break\n",
    "        c+=1    \n",
    "\n",
    "        if df.iloc[i][4]!=prev_count:\n",
    "            prev_string = ''\n",
    "            prev_count = df.iloc[i][4]\n",
    "        \n",
    "        a2 = df.iloc[i][2]\n",
    "        a3 = df.iloc[i][3]    \n",
    "        call_string = prev_string + TAGS[4]+ a2    \n",
    "        prev_string = prev_string + TAGS[2]+ a2 + TAGS[3] + a3\n",
    "        # print(a2)\n",
    "        # print('call: ',call_string)\n",
    "        # print('prev: ',call_string)\n",
    "        # print(a3)\n",
    "        mn_ar_1.append(call_string)\n",
    "        mn_ar_2.append(a3)\n",
    "\n",
    "    ndf = pd.DataFrame(            \n",
    "                list(zip(\n",
    "                    mn_ar_1,mn_ar_2                  \n",
    "                    )),\n",
    "\n",
    "                columns =[\n",
    "                    'Call',\n",
    "                    'Response'\n",
    "                    ]\n",
    "                    ) \n",
    "\n",
    "    df['Profile'] = df['Gender'] + ' ' +df['Age']\n",
    "    ndf['Call'] = TAGS[0]+ df['Profile'] + df['TAG'] + ndf['Call']\n",
    "\n",
    "    print(ndf.shape)\n",
    "    fl_dst = lst_files[fl_no][:-3] + '.csv'\n",
    "    path_dst = os.path.join(dst_dir,fl_dst)\n",
    "    ndf.to_csv(path_dst,index=False)       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 C:\\Users\\ydjoe\\Documents\\nlp\\personalized-dialog-dataset\\small\\txt files\\personalized-dialog-task1-API-calls-dev.txt\n",
      "1 C:\\Users\\ydjoe\\Documents\\nlp\\personalized-dialog-dataset\\small\\txt files\\personalized-dialog-task1-API-calls-trn.txt\n",
      "2 C:\\Users\\ydjoe\\Documents\\nlp\\personalized-dialog-dataset\\small\\txt files\\personalized-dialog-task1-API-calls-tst-OOV.txt\n",
      "3 C:\\Users\\ydjoe\\Documents\\nlp\\personalized-dialog-dataset\\small\\txt files\\personalized-dialog-task1-API-calls-tst.txt\n",
      "4 C:\\Users\\ydjoe\\Documents\\nlp\\personalized-dialog-dataset\\small\\txt files\\personalized-dialog-task2-API-refine-dev.txt\n",
      "5 C:\\Users\\ydjoe\\Documents\\nlp\\personalized-dialog-dataset\\small\\txt files\\personalized-dialog-task2-API-refine-trn.txt\n",
      "6 C:\\Users\\ydjoe\\Documents\\nlp\\personalized-dialog-dataset\\small\\txt files\\personalized-dialog-task2-API-refine-tst-OOV.txt\n",
      "7 C:\\Users\\ydjoe\\Documents\\nlp\\personalized-dialog-dataset\\small\\txt files\\personalized-dialog-task2-API-refine-tst.txt\n",
      "8 C:\\Users\\ydjoe\\Documents\\nlp\\personalized-dialog-dataset\\small\\txt files\\personalized-dialog-task3-options-dev.txt\n"
     ]
    }
   ],
   "source": [
    "for i in range(0,9):\n",
    "    fl_no = i\n",
    "    path_final = os.path.join(src_dir,lst_files[fl_no])\n",
    "    print(i,path_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6008, 5)\n",
      "(6008, 2)\n",
      "(6016, 5)\n",
      "(6016, 2)\n",
      "(6014, 5)\n",
      "(6014, 2)\n",
      "(5931, 5)\n",
      "(5931, 2)\n",
      "(9502, 5)\n",
      "(9502, 2)\n",
      "(9488, 5)\n",
      "(9488, 2)\n",
      "(9450, 5)\n",
      "(9450, 2)\n",
      "(9453, 5)\n",
      "(9453, 2)\n"
     ]
    }
   ],
   "source": [
    "for i in range(0,8):\n",
    "    fl_no = i\n",
    "    path_final = os.path.join(src_dir,lst_files[fl_no])\n",
    "    df = convert_to_df(path_final)\n",
    "    df = add_context(df)\n",
    "    parse_from_df(df)\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "540e2923c3b50c5b50181b56164d273ff885d61dafa41268e9f428c1d3e4caa0"
  },
  "kernelspec": {
   "display_name": "Python 3.9.6 ('venv')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
